# Evaluation report for model="Llama-4-Scout-17B-16E-Instruct" on dataset="rubriceval_general/rubrics.json"

## Overview
**Score**: 7.65 Â± 0.11

## Details
**Model**: Llama-4-Scout-17B-16E-Instruct

**Dataset**: rubriceval_general/rubrics.json

**N Instructions**: 392

**Evaluator**: gpt-4o-2024-08-06_CoT_v-1

**Summarizer**: None

**Report Date**: 2025-04-14

**Version**: rubric_eval==0.1.0

**Report Cost**: $48.46

**Report Time**: 11.84 minutes

## Analysis of outputs
**Avg. length of output**: 4134 characters

**Avg. list presence**: 74.5 %

**Avg. number of list items**: 16.2 list items


