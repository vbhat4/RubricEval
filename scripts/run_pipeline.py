model_to_inference_api = {
    "gpt-4o-2024-08-06": "OpenAI",
    "gpt-4o-mini-2024-07-18": "OpenAI",
    "o3-mini-2025-01-31": "OpenAI",
    "gemini-2.5-pro-preview-03-25": "Google",
    "gemini-2.0-flash": "Google",
    "gemini-2.0-flash-lite": "Google",
    "Llama-4-Maverick-17B-128E-Instruct-FP8": "TogetherAI",
    "Llama-4-Scout-17B-16E-Instruct": "TogetherAI",
    "Llama-3.3-70B-Instruct-Turbo": "TogetherAI",
    "DeepSeek-R1": "TogetherAI",
    "DeepSeek-V3": "TogetherAI",
    "QwQ-32B": "TogetherAI",
    "Qwen2.5-72B-Instruct-Turbo": "TogetherAI",
    "Qwen2.5-7B-Instruct-Turbo": "TogetherAI",
    "Mistral-Small-24B-Instruct-2501": "TogetherAI",
    "Mixtral-8x22B-Instruct-v0.1": "TogetherAI",
    "Mixtral-8x7B-Instruct-v0.1": "TogetherAI",
    "gemma-3-27b-it": "TogetherAI",
    "gemma-2-27b-it": "TogetherAI",
    "gemma-2-9b-it": "TogetherAI"
    # TODO: add remaining models
}

# TODO: automatically evaluate all models in parallel