gpt-4o-2024-08-06_CoT_v0:
  prompt_template: "gpt-4o-2024-08-06_CoT_v0/prompt.txt"
  fn_completions: "openai_completions"
  completions_kwargs:
    model_name: "gpt-4o-2024-08-06"
    max_tokens: 4096
    temperature: 0
    tool_choice:
      type: function
      function:
        name: "make_evaluation_report"
    tools:
      - type: function
        function:
          name: "make_evaluation_report"
          description: "Aggregates all the scores and feedback over instructions to make the final evaluation report."
          strict: true
          parameters:
            type: "object"
            properties:
              explanation:
                type: "string"
                description: "Brief justification for the chosen performance level."
              final_score:
                type: "number"
                description: "Likert scale score between 1 and 10 that quantifies the overall quality of the LLM's output."
            additionalProperties: false
            required: [ "explanation", "final_score" ]
  batch_size: 1
  fn_completion_parser: null
