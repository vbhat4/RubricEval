gpt-4o-mini-2024-07-18_CoT_v0:
  prompt_template: "gpt-4o-2024-08-06_CoT_v0/prompt.txt"
  fn_completions: "openai_completions"
  completions_kwargs:
    model_name: "gpt-4o-mini-2024-07-18"
    max_tokens: 8192
    temperature: 0
    tool_choice:
      type: function
      function:
        name: "make_evaluation_report"
    tools:
      - type: function
        function:
          name: "make_evaluation_report"
          description: "Aggregates all the scores and feedback over criteria and instructions to make the final evaluation report."
          strict: true
          parameters:
            type: "object"
            properties:
              rubric_grading:
                type: "array"
                description: "The evaluation for each criterion in the analytic rubric, represented as a list of dictionaries. Each dictionary provides feedback, an explanation, and the final score for the LLM output on that criterion."
                items:
                  type: "object"
                  description: "The evaluation for a single criterion in the rubric."
                  properties:
                    criterion:
                      type: "string"
                      description: "The descriptive name of the criterion. This must match exactly with the criterion in the rubric."
                    feedback:
                      type: "string"
                      description: "A concise but complete explanation of what the LLM did well and what it did poorly on that criterion."
                    explanation:
                      type: "string"
                      description: "A concise but complete explanation of why you chose the specific performance level for that criterion, referencing the rubric and specific elements of the LLM's output."
                    performance:
                      type: "string"
                      enum: [ "excellent", "good", "fair", "poor" ]
                      description: "The level of performance the LLM achieved on that criterion."
                  additionalProperties: false
                  required: [ "criterion", "feedback", "explanation", "performance" ]
            additionalProperties: false
            required: [ "rubric_grading" ]
  batch_size: 1
  fn_completion_parser: "json_parser"
  completion_parser_kwargs:
    annotation_key: "rubric_grading"
